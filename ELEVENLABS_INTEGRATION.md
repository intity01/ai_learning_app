# üé§ ElevenLabs Integration Guide

## üéØ Challenge: ElevenLabs + Google Cloud AI

**Goal:** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡πá‡∏ô **voice-driven, conversational, intelligent** language learning app

---

## üìã Features ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥

### **1. Voice Tutor (AI + Voice)** ü§ñüé§
- ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ **‡∏û‡∏π‡∏î‡∏Å‡∏±‡∏ö AI Tutor** ‡πÑ‡∏î‡πâ
- AI ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ **natural voice**
- ‡πÉ‡∏ä‡πâ **Gemini API** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI responses
- ‡πÉ‡∏ä‡πâ **ElevenLabs TTS** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î

### **2. Pronunciation Practice** üó£Ô∏è
- ‡πÉ‡∏ä‡πâ **ElevenLabs Speech-to-Text** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
- ‡πÉ‡∏ä‡πâ **ElevenLabs TTS** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
- ‡πÅ‡∏™‡∏î‡∏á feedback ‡∏ß‡πà‡∏≤‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

### **3. Vocabulary Pronunciation** üìö
- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏° Play Sound ‡πÉ‡∏ô Vocabulary Page
- ‡πÉ‡∏ä‡πâ **ElevenLabs TTS** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ (‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô, ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)

---

## üõ†Ô∏è Implementation

### **Step 1: Get ElevenLabs API Key**

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà [ElevenLabs](https://elevenlabs.io/)
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á account (‡∏ü‡∏£‡∏µ trial)
3. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà API Keys section
4. Copy API Key

### **Step 2: Install Dependencies**

```yaml
# pubspec.yaml
dependencies:
  http: ^1.1.0  # ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
  google_generative_ai: ^0.2.0  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini
  record: ^5.0.4  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Speech-to-Text
  permission_handler: ^11.0.0  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö permissions
```

### **Step 3: Create Voice Service**

```dart
// lib/services/voice_service.dart
import 'package:http/http.dart' as http;
import 'dart:convert';
import 'dart:io';

class VoiceService {
  final String apiKey = 'YOUR_ELEVENLABS_API_KEY';
  final String baseUrl = 'https://api.elevenlabs.io/v1';
  
  // Text-to-Speech
  Future<Uint8List> textToSpeech(String text, {String voiceId = '21m00Tcm4TlvDq8ikWAM'}) async {
    try {
      final response = await http.post(
        Uri.parse('$baseUrl/text-to-speech/$voiceId'),
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': apiKey,
        },
        body: json.encode({
          'text': text,
          'model_id': 'eleven_multilingual_v2',
          'voice_settings': {
            'stability': 0.5,
            'similarity_boost': 0.5,
          },
        }),
      );
      
      if (response.statusCode == 200) {
        return response.bodyBytes;
      } else {
        throw Exception('TTS failed: ${response.statusCode}');
      }
    } catch (e) {
      throw Exception('TTS error: $e');
    }
  }
  
  // Speech-to-Text (‡πÉ‡∏ä‡πâ ElevenLabs Speech-to-Text ‡∏´‡∏£‡∏∑‡∏≠ Google Speech-to-Text)
  Future<String> speechToText(Uint8List audioData) async {
    // TODO: Implement Speech-to-Text
    // ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ Google Cloud Speech-to-Text API ‡πÅ‡∏ó‡∏ô‡πÑ‡∏î‡πâ
    return '';
  }
}
```

### **Step 4: Create AI Service (Gemini)**

```dart
// lib/services/ai_service.dart
import 'package:google_generative_ai/google_generative_ai.dart';

class AIService {
  final String apiKey = 'YOUR_GEMINI_API_KEY';
  late final GenerativeModel model;
  
  AIService() {
    model = GenerativeModel(
      model: 'gemini-pro',
      apiKey: apiKey,
    );
  }
  
  Future<String> sendMessage(String message, List<Map<String, String>> history) async {
    try {
      final prompt = '''
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Tutor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
‡∏ä‡πà‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£:
- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î
- ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤
- ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:
${history.map((h) => '${h['sender']}: ${h['text']}').join('\n')}

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: $message
AI Tutor:''';
      
      final response = await model.generateContent([Content.text(prompt)]);
      return response.text ?? '‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ';
    } catch (e) {
      throw Exception('AI error: $e');
    }
  }
}
```

### **Step 5: Update AI Tutor Page**

```dart
// lib/pages/ai_tutor_page.dart
import '../services/ai_service.dart';
import '../services/voice_service.dart';

class AITutorPage extends StatefulWidget {
  // ...
  
  final AIService aiService = AIService();
  final VoiceService voiceService = VoiceService();
  bool isListening = false;
  
  Future<void> _sendMessage(String text) async {
    // Add user message
    setState(() {
      _messages.add({
        'sender': 'user',
        'text': text,
        'time': _getCurrentTime(),
      });
    });
    
    // Get AI response
    try {
      final response = await aiService.sendMessage(text, _messages);
      
      setState(() {
        _messages.add({
          'sender': 'ai',
          'text': response,
          'time': _getCurrentTime(),
        });
      });
      
      // Play AI response with voice
      await _playVoice(response);
    } catch (e) {
      // Handle error
    }
  }
  
  Future<void> _playVoice(String text) async {
    try {
      final audioData = await voiceService.textToSpeech(text);
      // Play audio using audio player
      // ...
    } catch (e) {
      print('Voice error: $e');
    }
  }
  
  Future<void> _startListening() async {
    // Start recording
    // ...
  }
  
  Future<void> _stopListening() async {
    // Stop recording and convert to text
    // ...
    final text = await voiceService.speechToText(audioData);
    if (text.isNotEmpty) {
      _sendMessage(text);
    }
  }
}
```

---

## üéØ ElevenLabs Challenge Requirements Checklist

- [ ] ‡πÉ‡∏ä‡πâ **ElevenLabs Agents** + **Google Cloud Vertex AI/Gemini**
- [ ] ‡πÉ‡∏´‡πâ‡πÅ‡∏≠‡∏õ‡∏°‡∏µ **natural, human voice** ‡πÅ‡∏•‡∏∞ **personality**
- [ ] ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ **interact ‡∏ú‡πà‡∏≤‡∏ô speech** ‡πÑ‡∏î‡πâ
- [ ] ‡πÉ‡∏ä‡πâ **React SDK** ‡∏´‡∏£‡∏∑‡∏≠ **server-side calls** ‡∏ö‡∏ô Google Cloud
- [ ] Deploy ‡∏ö‡∏ô Google Cloud
- [ ] ‡∏™‡∏£‡πâ‡∏≤‡∏á Demo Video (3 minutes)

---

## üìù Next Steps

1. **Get API Keys** - ElevenLabs + Google Cloud
2. **Implement Services** - VoiceService + AIService
3. **Update UI** - ‡πÄ‡∏û‡∏¥‡πà‡∏° voice features
4. **Test** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö voice interaction
5. **Deploy** - Deploy ‡∏ö‡∏ô Google Cloud

---

**‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏•‡πâ‡∏ß!** üöÄ


